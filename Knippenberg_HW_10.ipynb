{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b0a52e",
   "metadata": {},
   "source": [
    "### Assignment 10\n",
    "\n",
    "In this assignment you will experiment on your own. Using a health dataset of your choice (check with us if you are not sure), write code to demonstrate the following Pandas functions:\n",
    "\n",
    "- Melt\n",
    "- Pivot\n",
    "- Aggregation\n",
    "- Iteration\n",
    "- Groupby\n",
    "\n",
    "Here are some datasets you can use if you don’t have one:\n",
    "- https://archive.ics.uci.edu/ml/datasets/Breast+Cancer\n",
    "- https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008 --I'm choosing this one\n",
    "- https://archive.ics.uci.edu/ml/datasets/Arrhythmia\n",
    "\n",
    "Each function demonstration will be for 30 points for a total of 150 points. Ensure that you include comments within your code and follow the rubric as a guide. Submit using your GitHub site. Ask if you have any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08a13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2086dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('diabetic_data.csv')\n",
    "diabetes = pd.DataFrame(diabetes)\n",
    "diabetes.info()\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to explore (1) data types in the object columns and (2) What this string data entails (categorical, binary, nominal, etc).\n",
    "\n",
    "#The most common reason for an 'object' dtype is that the column holds variable types of data. \n",
    "#Pandas is known for using 'object' as a catch-all for columns that don't fit into a specific numeric or string type. However, a quirk of Pandas is ALSO to label \"string\" datatypes as \"objects.\"\n",
    "\n",
    "diabetes_expl = diabetes.copy()\n",
    "\n",
    "obj_col_metadata = []\n",
    "obj_col_md_valstr = [] #These will allow us to inspect the stats of the object columns - what datatypes are in there? How many? of what string values? Because we're going to make them consistent and possibly convert them to binary if it makes sense to do so.\n",
    "\n",
    "obj_cols = diabetes_expl.select_dtypes(include='object').columns #we are batch-isolating the 'object' columns to see what's in there\n",
    "for n in obj_cols: #for each object column\n",
    "    t2d_object_types = diabetes_expl[n].apply(type).value_counts() #type - find the datatypes in/of the object columns and how many of each type\n",
    "    for dtype, count in t2d_object_types.items(): #and ... \n",
    "        obj_col_metadata.append({'column': n, 'data_type': str(dtype), 'dt_count': count}) #put the types and type-counts for each column in the empty list\n",
    "    \n",
    "    t2d_object_values = diabetes_expl[n].value_counts(dropna=False) #value_counts - list the specific values (assuming they are at least categorical) and how many of each there are. We care about \"how many\" mostly for potential conversion or manipulation, not yet for data analysis.\n",
    "    for val, count in t2d_object_values.items(): #and ... \n",
    "        obj_col_metadata.append({'column': n, 'val_type': str(val), 'val_count': count}) #put the values and value-counts for each column in the same list. 'columns' will be overwritten by this second pass, but that's totally fine. \n",
    "\n",
    "    t2d_object_values_2 = diabetes_expl[n].value_counts(dropna=False) #Another organization of the same information. A bit shorter to read.\n",
    "    value_summary = \"; \".join([f\"{str(val)} ({count})\" for val, count in t2d_object_values_2.items()])\n",
    "    obj_col_md_valstr.append({'column': n, 'data_type': str(dtype), 'dt_count': count, 'value summary': value_summary})\n",
    "\n",
    "\n",
    "# Convert the output to a DataFrame, so we can then ... \n",
    "obj_col_metadata_df = pd.DataFrame(obj_col_metadata)\n",
    "obj_col_md_valstr_df = pd.DataFrame(obj_col_md_valstr)\n",
    "\n",
    "# ... export to CSV\n",
    "obj_col_metadata_df.to_csv('obj_col_metadata.csv', index=False)\n",
    "obj_col_md_valstr_df.to_csv('obj_col_md_valstr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427f72c",
   "metadata": {},
   "source": [
    "We're going to deal with Object datatypes and turn them ALL to Strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4a8daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  string\n",
      " 3   gender                    101766 non-null  string\n",
      " 4   age                       101766 non-null  string\n",
      " 5   weight                    101766 non-null  string\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  string\n",
      " 11  medical_specialty         101766 non-null  string\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  string\n",
      " 19  diag_2                    101766 non-null  string\n",
      " 20  diag_3                    101766 non-null  string\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    string\n",
      " 23  A1Cresult                 17018 non-null   string\n",
      " 24  metformin                 101766 non-null  string\n",
      " 25  repaglinide               101766 non-null  string\n",
      " 26  nateglinide               101766 non-null  string\n",
      " 27  chlorpropamide            101766 non-null  string\n",
      " 28  glimepiride               101766 non-null  string\n",
      " 29  acetohexamide             101766 non-null  string\n",
      " 30  glipizide                 101766 non-null  string\n",
      " 31  glyburide                 101766 non-null  string\n",
      " 32  tolbutamide               101766 non-null  string\n",
      " 33  pioglitazone              101766 non-null  string\n",
      " 34  rosiglitazone             101766 non-null  string\n",
      " 35  acarbose                  101766 non-null  string\n",
      " 36  miglitol                  101766 non-null  string\n",
      " 37  troglitazone              101766 non-null  string\n",
      " 38  tolazamide                101766 non-null  string\n",
      " 39  examide                   101766 non-null  string\n",
      " 40  citoglipton               101766 non-null  string\n",
      " 41  insulin                   101766 non-null  string\n",
      " 42  glyburide-metformin       101766 non-null  string\n",
      " 43  glipizide-metformin       101766 non-null  string\n",
      " 44  glimepiride-pioglitazone  101766 non-null  string\n",
      " 45  metformin-rosiglitazone   101766 non-null  string\n",
      " 46  metformin-pioglitazone    101766 non-null  string\n",
      " 47  change                    101766 non-null  string\n",
      " 48  diabetesMed               101766 non-null  string\n",
      " 49  readmitted                101766 non-null  string\n",
      "dtypes: int64(13), string(37)\n",
      "memory usage: 38.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#max_glu_serum and A1Cresult are Object classes comprising 2 datatypes:  strings AND floats. But the floats are all nan? Well that's too bad, the floats are just not available. Weird that Python registers that as float columns though. \n",
    "#All other Object classes are only strings\n",
    "\n",
    "obj_cols2 = diabetes.select_dtypes(include='object').columns\n",
    "for n in obj_cols2:\n",
    "    if n in diabetes.columns:\n",
    "        diabetes[n] = diabetes[n].astype(\"string\")\n",
    "\n",
    "print(diabetes.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbfa3e",
   "metadata": {},
   "source": [
    "Now we're going to deal with missing values (or null, blank, NaN, not applicable, not recorded, unknown). They are NOT consistently rendered. I am using the .csv files I generated to explore the values that are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df30a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses nan: max_glu_serum and A1Cresult, as we noted above when dealing with object types. But the nan values were formerly floats, which is too bad, as those measures are just not available.\n",
    "# Uses ?: Race, weight, payer_code, medical_specialty, diag_1, diag_2, and diag_3\n",
    "# Uses Unknown/Invalid: gender\n",
    "\n",
    "# I understand what they're trying to convey for gender, and ... \n",
    "# even though I HATE the ?, I don't want to expand the field by replacing it with \"Unknown\", especially if the code fields are limited in size. \n",
    "# Alternatively replacing ? with a blank or NaN would be misleading in some cases. \n",
    "\n",
    "# I think ... I think the only thing I'm going to change is the text 'nan' to an actual .isna value in max_glu_serum and A1Cresult. Not really necessary, but I don't want a 'fake' NaN.\n",
    "\n",
    "NaN_cols = [\"max_glu_serum\", 'A1Cresult']\n",
    "\n",
    "for n in NaN_cols:\n",
    "    if n in diabetes.columns:\n",
    "        diabetes[n] = diabetes[n].replace('nan',np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa50535",
   "metadata": {},
   "source": [
    "We're going to check if encounter_id or patient_nbr are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09892e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 101766 unique encounters in the dataset of 101766 records.\n",
      "There are 71518 unique patients in the dataset of 101766 records.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_encounters = diabetes['encounter_id'].nunique()\n",
    "print(f\"There are {unique_encounters} unique encounters in the dataset of 101766 records.\")\n",
    "\n",
    "unique_patients = diabetes['patient_nbr'].nunique()\n",
    "print(f\"There are {unique_patients} unique patients in the dataset of 101766 records.\")\n",
    "\n",
    "#Now we're ready to do the homework!\n",
    "\n",
    "#Knowing we are working with unique ENCOUNTERS or PATIENTS might help us decide which things to melt, pivot, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c295c",
   "metadata": {},
   "source": [
    "Melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9375ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patient_nbr upto_3_Dx  DxCode\n",
      "0           8222157    diag_1  250.83\n",
      "1          55629189    diag_1     276\n",
      "2          86047875    diag_1     648\n",
      "3          82442376    diag_1       8\n",
      "4          42519267    diag_1     197\n",
      "...             ...       ...     ...\n",
      "305293    100162476    diag_3     458\n",
      "305294     74694222    diag_3     787\n",
      "305295     41088789    diag_3     296\n",
      "305296     31693671    diag_3     998\n",
      "305297    175429310    diag_3     787\n",
      "\n",
      "[305298 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#I'm going to melt the diagnoses by PATIENT_NBR. (Because unless our objectives for this dataset tell us otherwise, diagnoses SHOULD be more dependent on patient than encounter.)\n",
    "#In visualization, melting is good for seeing multiple variables/columns on one plot.\n",
    "\n",
    "dx_pt_melt = pd.melt(diabetes,id_vars='patient_nbr', value_vars=['diag_1', 'diag_2', 'diag_3'],var_name = 'upto_3_Dx', value_name = 'DxCode') \n",
    "#value_vars = the target variable names to melt, which contain the values we want, var_name = the NEW variable name comprising the variables we melted, value_name = the meaning of the old cell values in their new relationship to the ID variable\n",
    "print(dx_pt_melt)\n",
    "\n",
    "#This would make it very easy to filter by diagnosis ... or by patient! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467d827",
   "metadata": {},
   "source": [
    "Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6af30c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          encounter_id            \n",
      "A1Cresult           >7    >8  Norm\n",
      "insulin                           \n",
      "Down               443  1598   603\n",
      "No                1680  2197  2309\n",
      "Steady            1210  2737  1558\n",
      "Up                 479  1684   520\n"
     ]
    }
   ],
   "source": [
    "#Because this dataset has more than 101K rows, I'm struggling to see a situation where I would want to PIVOT this without doing anything else. \n",
    "# I think we're going to pivot insulin and A1C result, AND count the number of ENCOUNTERS. And in order to count, I need to use pivot_table instead of pivot.\n",
    "\n",
    "insulin_a1c_pivot = diabetes[['encounter_id', 'A1Cresult', 'insulin']].copy() #Reduced this to get rid of all the noise.\n",
    "insulin_a1c_pivot = pd.pivot_table(insulin_a1c_pivot,index='insulin',columns='A1Cresult',aggfunc='count') #index means 'row', columns is self-evident, and aggfunc is performed on the remaining variable. \n",
    "print(insulin_a1c_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2547982",
   "metadata": {},
   "source": [
    "Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6698edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      num_lab_procedures  num_medications  number_outpatient  \\\n",
      "mean           43.095641        16.021844           0.369357   \n",
      "std            19.674362         8.127566           1.267265   \n",
      "\n",
      "      number_emergency  number_inpatient  \n",
      "mean          0.197836          0.635566  \n",
      "std           0.930472          1.262863  \n"
     ]
    }
   ],
   "source": [
    "#Let's find the average number (and standard deviation) of lab procedures, medications, and outpatient, emergency, and inpatient encounters across all encounters!\n",
    "\n",
    "mean_std = diabetes.aggregate({'num_lab_procedures': ['mean', 'std'], #fairly basic\n",
    "                                'num_medications': ['mean', 'std'],\n",
    "                                'number_outpatient': ['mean', 'std'],\n",
    "                                'number_emergency': ['mean', 'std'],\n",
    "                                'number_inpatient': ['mean', 'std']})\n",
    "print(mean_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d74f3",
   "metadata": {},
   "source": [
    "Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique or resolved patients: 69769\n",
      "Conflicting patients: 1749\n",
      "   variable         category  percent\n",
      "0      race        Caucasian    74.88\n",
      "1      race  AfricanAmerican    18.06\n",
      "2      race         Hispanic     2.12\n",
      "3      race                ?     2.64\n",
      "4      race            Asian     0.70\n",
      "5      race            Other     1.62\n",
      "6    gender           Female    53.13\n",
      "7    gender             Male    46.86\n",
      "8    gender                ?     0.00\n",
      "9       age          [50-60)    17.36\n",
      "10      age          [80-90)    16.37\n",
      "11      age          [30-40)     3.75\n",
      "12      age          [60-70)    22.28\n",
      "13      age          [40-50)     9.55\n",
      "14      age          [70-80)    25.43\n",
      "15      age          [10-20)     0.75\n",
      "16      age         [90-100)     2.72\n",
      "17      age          [20-30)     1.57\n",
      "18      age           [0-10)     0.22\n",
      "19   weight                ?    95.93\n",
      "20   weight          [50-75)     1.09\n",
      "21   weight          [25-50)     0.12\n",
      "22   weight         [75-100)     1.65\n",
      "23   weight        [100-125)     0.77\n",
      "24   weight        [125-150)     0.18\n",
      "25   weight             <NA>     0.15\n",
      "26   weight           [0-25)     0.05\n",
      "27   weight        [150-175)     0.05\n",
      "28   weight             >200     0.00\n",
      "29   weight        [175-200)     0.01\n"
     ]
    }
   ],
   "source": [
    "# items(): to iterate over the (key,value) pairs: allows you to iterate over each column as a key-value pair, with the label as the key and the column values as a Series object. This method is consistent with the dictionary-like interface of a DataFrame.\n",
    "# iterrows(): iterate over the rows as (index,series) pairs: returns an iterator that yields index and row pairs, where each row is represented as a Series object, containing the data in each row.\n",
    "# itertuples(): iterate over the rows as namedtuples: will return an iterator yielding a named tuple for each row in the DataFrame. The first element of the tuple will be the rows corresponding index value, while the remaining values are the row values. This method is generally faster than iterrows() and preserves the data types of the row elements.\n",
    "\n",
    "#For this problem only, I am going to ASSUME ALL DATA WERE COLLECTED OVER A YEAR and iterate over demographic data (which SHOULD be pretty immutable) for unique patients as a percentage of the total unique patients (hopefully N = 71518). In my imagination, I have narrowed the timeframe to justify dropping patients whose demographic data is irreconcilable. \n",
    "#And I will use ITEMS to iterate. \n",
    "\n",
    "dm_demo_var = ['patient_nbr','race','gender','age','weight']\n",
    "dm_demo = diabetes[dm_demo_var].copy() #Making a smaller dataset to work with. \n",
    "#At this time and for this problem only, I'm going to quickly switch the 'Unknown/Invalid' values in 'gender' to '?'. There's only 3 of them. \n",
    "dm_demo['gender'] = dm_demo['gender'].replace('Unknown/Invalid', '?')\n",
    "\n",
    "duplicate_mask = dm_demo[dm_demo.duplicated('patient_nbr',keep = False)] #a mask applied to dm_demo to retain only the duplicated patients\n",
    "diff_demo_ct = duplicate_mask.groupby('patient_nbr')[['race','gender','age','weight']].nunique().count() \n",
    "\n",
    "#We want to see how many of the duplicate pt records have DIFFERENT (nunique) demographics between duplicates, when in theory these SHOULD be immutable characteristics. \n",
    "#Exceptions include things like weight or age, or any of these might not be captured during the encounter and might have a ? instead. \n",
    "\n",
    "#Well, 16,773 is a lot of duplicate patients with disparate demographic info.\n",
    "#I'm going to set up an if/elif/else situation, and hopefully the ? value accounts for most of the differences. \n",
    "\n",
    "def resolve_demog(dm_demo):\n",
    "    # Drop duplicate rows within the group, just in case\n",
    "    unique_rows = dm_demo.drop_duplicates(subset=['race', 'gender', 'age', 'weight'])\n",
    "    \n",
    "    if len(unique_rows) == 1: # IF = All columns identical\n",
    "        return unique_rows.iloc[0]\n",
    "\n",
    "    cleaned = unique_rows.replace('?', pd.NA) # ELIF = Condition is, every column has at most 1 non-null value. First, Make rows with '?' more pandas-friendly for null values. \n",
    "    nunique_non_na = cleaned.nunique(dropna=True) # Next, If each column has only 1 unique non-null value, we can safely collapse AND 'roll up' any ? to a single row with legit values.\n",
    "    if (nunique_non_na <= 1).all(): \n",
    "        collapsed = cleaned.ffill().bfill().iloc[0] # Fill ? with the non-null value\n",
    "        return collapsed\n",
    "    \n",
    "    dm_demo['conflict_flag'] = True # ELSE = Conflicting values remain — send to conflict dataframe\n",
    "    return dm_demo\n",
    "\n",
    "results = []\n",
    "conflicts = []\n",
    "\n",
    "for pid, dem in dm_demo.groupby('patient_nbr', group_keys=False): #Now I'm going to filter so I have a clean dataset of ONLY unique patient IDs with pretty certain demographics. I am eliminating 'conflicted' patients that have differing values for demographics. \n",
    "    resolved = resolve_demog(dem)\n",
    "    \n",
    "    if isinstance(resolved, pd.Series):\n",
    "        results.append(resolved)\n",
    "    else:\n",
    "        conflicts.append(resolved)\n",
    "\n",
    "dm_clean_final = pd.DataFrame(results).reset_index(drop=True) # Combine results\n",
    "total_nunique = dm_clean_final['patient_nbr'].nunique() #Eliminate any remaning duplicates. \n",
    "dm_conflict = pd.concat(conflicts, ignore_index=True) if conflicts else pd.DataFrame() #We don't do anything else with our conflicted patients, but we'll store them nonetheless. \n",
    "\n",
    "print(f\"Unique or resolved patients: {total_nunique}\")\n",
    "print(f\"Conflicting patients: {dm_conflict['patient_nbr'].nunique()}\")\n",
    "\n",
    "#NOW we're FINALLY going to iterate to find percentages for race, gender, age, and weight. \n",
    "demo_counts_for_pct = []\n",
    "\n",
    "for var, col_data in dm_clean_final[['race','gender','age','weight']].items(): #ITEMS, WITH COLUMNS AS KEYS AND COLUMN VALUES AS VALUES (THE PAIR)\n",
    "    counts = {}\n",
    "    for val in col_data: #The values in the pair\n",
    "        counts[val] = counts.get(val, 0) + 1 #the 1 allows us to keep counting as we iterate over val. \n",
    "    for category, count in counts.items(): #Now that we've counted everything, we apply .ITEMS again and iterate again, making percentages from our counts. \n",
    "        pct = round((count / total_nunique) * 100, 2)\n",
    "        demo_counts_for_pct.append({'variable': var, 'category': category, 'percent': pct}) #makes a nested list ... \n",
    "\n",
    "demo_pct_df = pd.DataFrame(demo_counts_for_pct) #makes the nested list a dataframe! \n",
    "print(demo_pct_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c61407",
   "metadata": {},
   "source": [
    "Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bf89eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Rx  num_pts\n",
      "0                   acarbose      236\n",
      "1              acetohexamide        1\n",
      "2             chlorpropamide       76\n",
      "3                glimepiride     4187\n",
      "4   glimepiride-pioglitazone        1\n",
      "5                  glipizide     9998\n",
      "6        glipizide-metformin        9\n",
      "7                  glyburide     8558\n",
      "8        glyburide-metformin      567\n",
      "9                    insulin    39577\n",
      "10                 metformin    16477\n",
      "11    metformin-pioglitazone        1\n",
      "12   metformin-rosiglitazone        2\n",
      "13                  miglitol       24\n",
      "14               nateglinide      579\n",
      "15              pioglitazone     5939\n",
      "16               repaglinide     1177\n",
      "17             rosiglitazone     5184\n",
      "18                tolazamide       33\n",
      "19               tolbutamide       21\n",
      "20              troglitazone        3\n"
     ]
    }
   ],
   "source": [
    "#Now I'm going to count the number of unique patients and .GROUPBY each medication. \n",
    "\n",
    "Rx = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "Yes_values = ['Steady', 'Up', 'Down'] # We don't include the 'no' values. ... and we don't care what kind of 'yes' value we get, we're just reducing it to No/Yes. \n",
    "\n",
    "mask = diabetes[Rx].isin(Yes_values).any(axis=1) #This mask gets rid of any records that have none of the medications\n",
    "Rx_filtered = diabetes[mask] #Keeps the records that have any of the medications\n",
    "Rx_pts_melt = pd.melt(Rx_filtered,id_vars='patient_nbr', value_vars=Rx,var_name = 'Rx', value_name = 'RxYes') \n",
    "#We are melting this to get our many medication columns into 1 medication column. \n",
    "# And because each patient will have some BUT NOT ALL medications, after melting, we will still have plenty of records with \"no\" in them. \n",
    "# A \"no\" record means the patient is not on THIS medication but is on something else.\n",
    "Rx_filtered2 = Rx_pts_melt[Rx_pts_melt['RxYes'].isin(Yes_values)] #So we're going to filter out all the \"No\"s again.\n",
    "#This time we have only yesses, but we still have patients represented multiple times ... due to multiple encounters and/or multiple medications.\n",
    "Rx_pts_agg = (Rx_filtered2.groupby('Rx',as_index = False).agg(num_pts = ('patient_nbr','nunique'))) #FINALLY, we're going to count unique patients (with the .agg function) and group them by medication (with .groupby)\n",
    "print(Rx_pts_agg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
